---
layout:     post
title:      reading-note-csapp
date:       2018-03-17 21:48:00
author:     "Hou"
header-img: "img/post-bg-computer-science.jpg"
tags:
    - note
    - csapp
---
第十二章-并发编程小结
============

### 12.1 基于进程的并发编程

![](/img/post/post-2018-02-28-55.jpg)


### 12.2 基于I/O多路复用的并发编程

I/O多路复用（I/O multiplexing）技术的基本思路是使用select函数，要求内核挂起进程，只有在一个或多个I/O事件发生后，才将控制返回给应用程序。

select函数处理类型为fd_set的集合，也叫作描述符集合。逻辑上，我们将描述符集合看成一个大小为n的位向量

bn-1,...,b1,b0

每个位bk对应于描述符k。当且仅当bk=1，描述符k才表明是描述符集合的一个元素。

针对我们的目的，select函数有两个输入：一个称为读集合的描述符集合（fdset）和该读集合的基数（n）。select函数会一直阻塞，直到读集合中至少有一个描述符准备好可以读。当且仅当一个从该描述符读取一个字节的请求不会阻塞时，描述符k就标识准备好可以读了。select有一个副作用，它修改参数fdset指向fd_set，指明读集合的一个子集，称为准备好集合（ready set），这个集合是由读集合中准备好可以读了的描述符组成的。

*12.2.1 基于I/O多路复用的并发事件驱动服务器*

I/O多路复用可以用作并发事件驱动（event-driven）程序的基础，在事件驱动程序中，某些事件会导致流向前推进。一般的思路是将逻辑流模型化为状态机。不严格的说，状态机（state machine）就是一组状态（state）、输入事件（input event）和转移（transition），其中转移是将状态和输入事件映射到状态。每个转移是将一个（输入状态，输入事件）对映射到一个输出状态。自循环（self-loop）是同一输入输出状态之间的转移。通常把状态机画成有向图，其中节点表示状态，有向弧表示转移，而弧上的标号表示输入事件。一个状态机从某种初始状态开始执行。每个输入事件都会引发一个从当前状态到下一个状态的转移。

服务器使用I/O多路复用，借助select函数检测输入事件的发生。当每个已连接描述符准备好可读时，服务器九尾相应的状态机执行转移，在这里就是从描述符读和写回一个文本行。

*12.2.2 I/O多路复用技术的优劣*

一个基于I/O多路复用的事件驱动服务器是运行在单一进程上下文中的，因此每个逻辑流都能访问该进程的全部地址空间。这使得在流之间共享数据变得很容易。事件驱动设计常常比基于进程的设计要高效得多，因为它们不需要进程上下文切换来调度新的流。

缺点是编码复杂，随并发粒度的减小，复杂性还会上升。这里的粒度是指每个逻辑流每个时间片执行的指令数量。


### 12.3 基于线程的并发编程

线程（thread）就是运行在进程上下文中的逻辑流。线程由内核自动调度。每个线程都有它自己的逻辑上下文（thread context），包括一个唯一的整数线程ID（Thread ID，TID）、栈、栈指针、程序计数器、通用目的寄存器和条件码。所有的运行在一个进程里的线程共享该进程的整个虚拟地址空间。

*12.3.1 线程执行模型*

每个进程开始生命周期时都是单一线程，这个线程称为主线程（main thread）。在某一时刻，主线程创建一个对等线程（peer thread），从这个时间点开始，两个线程就并发地运行。最后，因为主线程执行一个慢速系统调用，例如read或者sleep，控制就会通过上下文切换传递到对等线程。对等线程会执行一段时间，然后控制传递回主线程。

在一些重要的方面，线程执行是不同于进程的。因为一个线程的上下文要比一个进程的上下文小得多，线程的上下文切换要比进程的上下文切换快的多。另一个不同就是线程不像进程那样，不是按照严格的斧子层次来组织的。和一个进程相关的线程组成一个对等（线程）池，独立于其他进程创建的线程。主线程和其他线程的区别仅在于它总是进程中第一个运行的线程。对等（线程）池概念的主要影响是，一个线程可以杀死它的任何对等线程，或者等待它的任意对等线程种植。另外，每个对等线程都能读写相同的共享数据。


### 12.4 多线程程序中的共享变量

*12.4.1 线程内存模型*

一组并发线程除了有自己独立的线程上下文，它们共享进程上下文的声誉部分。这包括整个用户虚拟地址空间，它是由只读文本（代码）、读/写数据、堆以及所有的共享库代码和数据区域组成的。线程也共享相同的打开文件的集合。

*12.4.2 将变量映射到内存*

- 全局变量：定义在函数之外的变量。在运行时，虚拟内存的读/写区域只包含每个全局变量的一个实例，任何线程都可以引用。

- 本地自动变量：定义在函数内部但是没有static属性的变量。在运行时，每个线程的栈都包含它自己的所有本地自动变量的实例。

- 本地静态变量：定义在函数内部并有static属性的变量。


### 12.5 用信号量同步线程

*12.5.1 进度图*

进度图（progress graph）将n个并发线程的执行模型化为一条n维笛卡尔空间中的轨迹线。每条轴k对应于线程k的进度。每个点（I1,I2,...In）代表线程k（k=1,...,n）以及完成了指令Ik这一状态。图的原点对应于没有任何线程完成一条指令的初始状态。

进度图将指令执行模型化为从一种状态到另一种状态的转换（transition）。转换被表示为一条从一点到相邻点的有向边。合法的转换时向右（线程1中的一条指令完成）或者向上（线程2中的一条指令完成）的。两条指令不能再同一时刻完成

![](/img/post/post-2018-02-28-56.jpg)

![](/img/post/post-2018-02-28-59.jpg)

对于线程i，操作共享变量cnt内容的指令构成了一个临界区（critical section），这个临界区不应该和其他进程的临界区交替执行。换句话说，我们想要确保每个线程在执行它的临界区中的指令时，拥有对共享变量的互斥的访问（mutually exclusive access）。通常这种现象称为互斥（mutual exclusion）。

在进度图中，两个临界区的交际形成的状态空间区域称为不安全区（unsafe region）。

![](/img/post/post-2018-02-28-57.jpg)

*12.5.2 信号量*

信号量（semaphore）是具有非负整数值得全局变量，只能由两种特殊的操作来处理，称为P和V：

- P（s）：如果s是非零的，那么P将s减一，并且立即返回。如果s为零，那么就挂起这个线程，直到s变为非零，而一个V操作会重启这个线程。在重启之后，P操作将s减一，并将控制返回给调用者。

V（s）：V操作将s加1.如果有任何线程阻塞在P操作等待s变成非零，那么V操作会重启这些线程中的一个，然后该线程将s减一，完成它的P操作。

*12.5.3 使用信号量来实现互斥*

信号量确保对共享变量互斥访问的方法是，将每个共享变量与一个信号量s联系起来，然后用P（s）和V（s）操作将相应的临界区包围起来。

以这种方式来保护共享变量的信号量叫做二元信号量（binary semaphore），因为它的值总是0或者1.以提供互斥为目的的二元信号量常常也成为互斥锁（mutex）。在一个互斥锁上执行P操作称为对互斥锁加锁。类似的，执行V操作称为对互斥锁解锁。对一个互斥锁加了锁但是还没有解锁的线程称为占用这个互斥锁。一个被用作一组可用资源的计数器的信号量被称为计数信号量。

![](/img/post/post-2018-02-28-58.jpg)

*12.5.4 利用信号量来调度共享资源*

1. 生产者-消费者问题

生产者和消费者线程共享一个有n个槽的有限缓冲区。生产者线程反复地生产新的项目（item），并把它们插入到缓冲区中。消费者线程不断地从缓冲区中取出这些项目，然后消费它们。

![](/img/post/post-2018-02-28-60.jpg)

因为插入和取出项目都涉及更新共享变量，所以我们必须保证对缓冲区的访问是互斥的。但是只保证互斥访问是不够的，我们还需要调度对缓冲区的访问。

2. 读者-写者问题

一组并发的线程要访问一个共享对象，例如一个驻村中的数据结构，或者一个磁盘上的数据库。有些线程只读对象，而其他的线程只修改对象。修改对象的线程叫做写者。只读对象的线程叫做读者。写者必须拥有对对象的独占的访问，而读者可以和无限多个其他的读者共享对象。一般来说，有无限多个并发的读者和写者。

![](/img/post/post-2018-02-28-61.jpg)

这个方法可能会导致饥饿（starvation），就是读者从不为0，写者无限等待。

*12.5.5 综合：基于预线程化的并发服务器*

一个基于预线程化的并发服务器通过生产者-消费者模型来降低这种开销。服务器是由一个主线程和一组工作者线程构成的。主线程不断地接受来自客户端的连接请求，并将得到的连接描述符放在一个有限缓冲区中。每一个工作者线程反复地从共享缓冲区中取出描述符，为客户端服务，然后等待下一个描述符。

![](/img/post/post-2018-02-28-62.jpg)


### 12.6 使用线程提高并行性

并行程序是一个运行在多个处理器上的并发程序

![](/img/post/post-2018-02-28-63.jpg)

在理想情况中，我们会期望运行时间随着核数的增加线性下降。也就是说，我们会期望线程数每增加一本，运行时间就下降一半。在t<5时，确实是这样，此时四个核中的每一个都忙于运行至少一个线程。随着线程数量的增加，运行时间实际上增加了一点，这是由于在一个核上多个线程上下文切换的开销。

并行程序的加速比（speedup）通常定义为
Sp=T1/Tp

这里p是处理器核的数量，Tk是在k个核上的运行时间。当T1是程序顺序执行版本的执行时间，Sp称为绝对加速比（absolute speedup）。当T1是程序并行版本在一个核上的执行时间时，Sp称为相对加速比（relative speedup）。绝对加速比比相对加速比能更真实地衡量并行的好处。


### 12.7 其他并发问题

*12.7.1 线程安全*

一个函数被称为线程安全的（thread-safe），当且仅当被多个并发线程反复地调用时，它会一直产生正确的结果。

我们能够定义出四个线程不安全函数类：

1. 不保护共享变量的函数。用V、P函数解决。

2. 保持*跨越多个调用的状态*的函数。

3. 返回指向静态变量的指针的函数。如果我们从并发线程中调用这些函数，正在被一个线程使用的结果会被另一个线程悄悄地覆盖。

4. 调用线程不安全函数的函数。如果被调用的函数是第2类函数，那么调用的函数也是线程不安全的。否则用互斥锁保护调用位置和任何得到的共享数据，可以使调用的函数是线程安全的。

*12.7.2 可重入性*

当可重入函数（reentrant function）被多个线程调用时，不会引用任何共享数据。如果所有的函数参数都是传值传递的，并且所有的数据引用都是本地的自动栈变量（非静态或全局变量），那么函数就是显式可重入的（explicitly reentrant）。

*12.7.4 竞争*

当一个程序的正确性依赖于一个线程要在另一个线程到达y点之前到达它的控制流中的x点时，就会发生竞争（race）。

*12.7.5 死锁*

![](/img/post/post-2018-02-28-64.jpg)

死锁（deadlock）指的是一组线程被阻塞了，等待一个永远也不会为真的条件。

使用二元信号量来实现互斥时，可以用以下规则来避免死锁：

- 互斥锁加锁顺序规则：给定所有互斥操作的一个全序，如果每个线程都是以一种顺序获得互斥锁并以相反的顺序释放，那么这个程序就是无死锁的。

![](/img/post/post-2018-02-28-65.jpg)